{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import pickle\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(6, 3, 5)\n",
    "        self.conv2 = nn.Conv2d(3, 2, 5)\n",
    "        \n",
    "        # Max-pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Linear layers\n",
    "        self.fc1 = nn.Linear(125 * 125 * 2, 2000)\n",
    "        self.fc2 = nn.Linear(2000, 1500)\n",
    "        self.fc3 = nn.Linear(1500, 1108)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 125 * 125 * 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = (self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HEPG2-01',\n",
       " 'HEPG2-02',\n",
       " 'HEPG2-03',\n",
       " 'HEPG2-04',\n",
       " 'HEPG2-05',\n",
       " 'HEPG2-06',\n",
       " 'HEPG2-07',\n",
       " 'HUVEC-01',\n",
       " 'HUVEC-02',\n",
       " 'HUVEC-03',\n",
       " 'HUVEC-04',\n",
       " 'HUVEC-05',\n",
       " 'HUVEC-06',\n",
       " 'HUVEC-07',\n",
       " 'HUVEC-08',\n",
       " 'HUVEC-09',\n",
       " 'HUVEC-10',\n",
       " 'HUVEC-11',\n",
       " 'HUVEC-12',\n",
       " 'HUVEC-13',\n",
       " 'HUVEC-14',\n",
       " 'HUVEC-15',\n",
       " 'HUVEC-16',\n",
       " 'RPE-01',\n",
       " 'RPE-02',\n",
       " 'RPE-03',\n",
       " 'RPE-04',\n",
       " 'RPE-05',\n",
       " 'RPE-06',\n",
       " 'RPE-07',\n",
       " 'train.csv',\n",
       " 'train_controls.csv',\n",
       " 'U2OS-01',\n",
       " 'U2OS-02',\n",
       " 'U2OS-03']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TRAIN = os.path.join(os.getcwd(), 'data', 'recursion', 'train')\n",
    "os.listdir(PATH_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "RECURSION_DIR = os.path.join(DATA_DIR, 'recursion')\n",
    "RECURSION_TRAIN = os.path.join(RECURSION_DIR, 'train')\n",
    "RECURSION_TEST = os.path.join(RECURSION_DIR, 'test')\n",
    "CELL_TYPES = ['HEPG2', 'HUVEC', 'RPE', 'U2OS']\n",
    "PLATES = ['Plate1', 'Plate2', 'Plate3', 'Plate4']\n",
    "LETTER_TO_IX = {}\n",
    "for ix, letter in enumerate(string.ascii_uppercase[1:15]):\n",
    "    LETTER_TO_IX[letter] = ix \n",
    "IX_TO_LETTER = {v: k for k, v in LETTER_TO_IX.items()}\n",
    "\n",
    "def parse_filename(s, full_path=False):\n",
    "    ''' Returns row, col, site, channel of a string in the format of the kaggle filename. '''\n",
    "    #first _ is always 3rd index\n",
    "    if full_path:\n",
    "        s = s[-13:]\n",
    "    col = LETTER_TO_IX[s[0]]\n",
    "    row = int(s[1:3]) - 2\n",
    "    site = int(s[5:6]) - 1\n",
    "    channel = int(s[8:9]) - 1\n",
    "    return row, col, site, channel  \n",
    "\n",
    "def read_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE).astype(np.float32)/255.0\n",
    "    return img\n",
    "\n",
    "def read_parse_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE).astype(np.float32)/255.0\n",
    "    info = parse_filename(path, True)\n",
    "    return img, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plate:\n",
    "    def __init__(self, cell_type, plate_num):\n",
    "        self.images = np.zeros((22, 14, 2, 6, 512, 512), dtype=np.float32) - 1\n",
    "        self.labels = np.zeros((22, 14), dtype=np.int32) - 1 \n",
    "        self.cell_type = cell_type\n",
    "        self.plate_num = plate_num\n",
    "        \n",
    "    def load_images(self, files):\n",
    "        with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "            images, indices = zip(*executor.map(read_parse_image, files))\n",
    "        images = np.array(images)\n",
    "        indices = np.array(indices)\n",
    "        self.images[indices[:, 0], indices[:, 1], indices[:, 2], indices[:, 3]] = images\n",
    "        \n",
    "    def get_image(self, s):\n",
    "        ix = parse_filename(s)\n",
    "        return self.images[ix]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'<Plate: plate_num: {self.plate_num}, cell_type: {self.cell_type}>'\n",
    "\n",
    "class Experiment: \n",
    "    def __init__(self, cell_type, exp_num, split):\n",
    "        self.cell_type = cell_type\n",
    "        self.exp_num = exp_num\n",
    "        self.split = split \n",
    "        self.plates = []\n",
    "        \n",
    "    def load_plates(self):\n",
    "        exp_dir = os.path.join(RECURSION_DIR, self.split, '{}-{:02d}'.format(self.cell_type, self.exp_num))\n",
    "        for i, p in enumerate(PLATES):\n",
    "            plate = Plate(self.cell_type, i+1)\n",
    "            plate_dir = os.path.join(exp_dir, p)\n",
    "            plate_files = os.listdir(plate_dir)\n",
    "            plate_files = glob.glob(f'{plate_dir}/*.png')\n",
    "            plate.load_images(plate_files)\n",
    "            self.plates.append(plate)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'<Experiment: cell_type: {self.cell_type}, exp_num: {self.exp_num}, split: {self.split} >'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, root_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        id_, experiment, plate, well, sirna = self.data.iloc[idx]\n",
    "        image = np.zeros((6, 512, 512))\n",
    "        \n",
    "        for s in range(1):\n",
    "            for c in range(6):\n",
    "                img_name = f'{well}_s{s+1}_w{c+1}.png'\n",
    "                path = os.path.join(self.root, experiment, f'Plate{plate}', img_name)\n",
    "                image[c, :, :] = read_image(path)\n",
    "        sirna_label = np.array([sirna])\n",
    "            \n",
    "        sample = {'image': image, 'label': sirna_label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=4):\n",
    "    CSV_PATH = os.path.join(RECURSION_TRAIN, 'train.csv')\n",
    "    trainset = Dataset(CSV_PATH, RECURSION_TRAIN)\n",
    "    return torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "\n",
    "def train(net, trainloader, save_path, num_epoch=1):\n",
    "    '''\n",
    "    Function: train\n",
    "    arguments:\n",
    "        net - CNN model used for training\n",
    "        trainloader - Torch DataLoader object\n",
    "        save_path - path to save the trained model\n",
    "    '''\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    # Set up GPU device\n",
    "    # os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "    # torch.cuda.device(0)\n",
    "    \n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # net.to(device)\n",
    "    device = \"cpu\"\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data['image'].to(device, dtype=torch.float), data['label'].to(device, dtype=torch.long)\n",
    "            labels = torch.squeeze(labels)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f'Completed {i} iterations of training')\n",
    "            \n",
    "    torch.save(net.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 iterations of training\n",
      "Completed 10 iterations of training\n",
      "Completed 20 iterations of training\n",
      "Completed 30 iterations of training\n",
      "Completed 40 iterations of training\n",
      "Completed 50 iterations of training\n",
      "Completed 60 iterations of training\n",
      "Completed 70 iterations of training\n",
      "Completed 80 iterations of training\n",
      "Completed 90 iterations of training\n",
      "Completed 100 iterations of training\n",
      "Completed 110 iterations of training\n",
      "Completed 120 iterations of training\n"
     ]
    }
   ],
   "source": [
    "# Get trainloader\n",
    "trainloader = load_data()\n",
    "\n",
    "# Create net\n",
    "net = Net()\n",
    "\n",
    "# Train the model\n",
    "SAVE_PATH = os.path.join(os.getcwd(), 'models')\n",
    "train(net, trainloader, SAVE_PATH, num_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:recursion]",
   "language": "python",
   "name": "conda-env-recursion-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
